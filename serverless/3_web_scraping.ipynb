{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Tutorial\n",
    "\n",
    "This notebook demonstrates web scraping techniques using Python including:\n",
    "- Making HTTP requests with proper headers\n",
    "- Parsing HTML content with BeautifulSoup\n",
    "- Extracting specific content using CSS selectors\n",
    "- Understanding why User-Agent headers are important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "Import the required libraries for web scraping: requests for HTTP requests and BeautifulSoup for HTML parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for web scraping\n",
    "print(\"ğŸ“š Setting up the environment...\")\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt Without Headers\n",
    "\n",
    "First, try to access the webpage without proper headers to demonstrate why they're needed. Many websites block requests without User-Agent headers to prevent automated scraping."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's try without headers to demonstrate why they're needed\n",
    "print(\"ğŸŒ Attempting to access webpage without headers...\")\n",
    "\n",
    "url = \"https://www.ceu.edu/news/2025-11/cultivating-mindsets-and-practices-environmental-sustainability\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    print(f\"ğŸ“¡ Response status code: {response.status_code}\")\n",
    "\n",
    "    if response.status_code == 403:\n",
    "        print(\"âŒ Access forbidden! This demonstrates why we need proper headers.\")\n",
    "        print(\"â„¹ï¸  Websites often block requests without proper User-Agent headers\")\n",
    "        print(\"   to prevent automated scraping.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request With Proper Headers\n",
    "\n",
    "Now make the request with a User-Agent header to successfully retrieve the webpage content."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ Attempting to access webpage with proper headers...\n",
      "ğŸ“¡ Response status code: 200\n",
      "âœ… Successfully retrieved the webpage! Received 58864 bytes of data.\n"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "# Now let's try with proper headers\n",
    "print(\"ğŸŒ Attempting to access webpage with proper headers...\")\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    + \" Chrome/39.0.2171.95 Safari/537.36\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    print(f\"ğŸ“¡ Response status code: {response.status_code}\")\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch webpage: Status code {response.status_code}\")\n",
    "\n",
    "    content_length = len(response.content)\n",
    "    print(f\"âœ… Successfully retrieved the webpage! Received {content_length} bytes of data.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install https://selectorgadget.com/ to extract different parts of the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Extract Content\n",
    "\n",
    "Parse the HTML using BeautifulSoup and extract the page title and article paragraphs using CSS selectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Parsing webpage content...\n",
      "\n",
      "ğŸ“‘ Page Title:\n",
      "----------------------------------------\n",
      "Cultivating Mindsets and Practices for Environmental Sustainability | Central European University\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ Article Content:\n",
      "----------------------------------------\n",
      "November 24, 2025\n",
      "        CEU students at Grand Farm. Image credit: CEU/Sotiris Bekas.\n",
      "      This fall, field trips in Vienna to the Donau-Auen National Park and urban farms, as well as the launch of CEUâ€™s new Sustainability Hub, encourage students and CEU community members to develop habits for environmental stewardship and participate in localized efforts for climate resiliency. CEU aims to serve as a model for environmentally responsible practices in higher education, from research that shapes global sustainability efforts to operations and governance that drive meaningful change.â€œWhile the climate crisis requires action from everyone, institutions of higher education have a special obligation to do their part,â€ said CEU Interim Rector and President Carsten Q. Schneider. â€œAt CEU, we embrace our responsibility to shape future decision-makers and advance knowledge that supports a more sustainable world. Sustainability is not separate from our mission - it strengthens it.â€Â Â \n",
      "        CEU field trip to Grand Farm. Image credit: CEU/Sotiris Bekas.\n",
      "      Â Exploring Biodiversity and Water Management Along the DanubeÂ In September, students and faculty from CEUâ€™s Department of Environmental Sciences and Policy started their academic year with a field trip to Donau-Auen National Park, a floodplain landscape with active river revitalization projects reconnecting natural side waters to the Danube river.Â Â The visit exposed CEU students to sustainable water management and habitat restoration in Vienna. It also provided an informal opportunity to discuss environmental justice with faculty and peers, as well as which specific courses at CEU will support further learning on topics explored at the Donau-Auen National Park.Â Â Combining Ecological Science With Farming PracticesÂ Â In October, students from the departmentâ€™s Agroecology and Organic Gardening SystemsÂ  course traveled to Viennaâ€™s Grand Farm and the Laaerberg Community Garden, to meet with active gardeners and farmers and also participate in activities for volunteers and the public, including a garden tour and harvest festival. CEU has a multi-year collaboration with Laaerberg Community Garden, which is based in Favoriten near campus.Â Â The course, in conjunction with the visits, informs students how they can participate in localized opportunities to contribute to climate resiliency.â€¯Taught by Associate Professor Guntra Anda Aistara with CEU Environmental and Sustainability Officer Logan Strenchock, it offers a theoretical and practical introduction to agroecology and organic farming.Â Â Pathways Toward SustainabilityÂ The universityâ€™s new Sustainability Hub, an internal platform for students, faculty and staff, plays a role in connecting the CEU community with volunteering opportunities for environmental activism and outreach with local Vienna-based sites and organizations. The hub also offers extensive information and resources on using land-based public transport for work travel purposes.Â Â Additionally, it provides campus sustainability best practices on topics such as reducing printing requirements and reducing energy consumption related to data processing and digital storage for research and documentation purposes. As part of the hubâ€™s events and thematic program series DIY:CEU, CEUâ€™s Student Engagement Office, in collaboration with Strenchock, will offer a series of on campus education workshops this month dedicated to reuse, repair and self-sufficiency to build skills for reducing material consumption reduction the university community. Finally, the hub features current research, teaching and learning on environmental mitigation topics, largely connected to CEUâ€™s Department of Environmental Sciences and Policy.Â \n",
      "        CEU field trip to Grand Farm. Image credit: CEU/Sotiris Bekas.\n",
      "      Also related to this work, CEUâ€™s Sustainability Advisory Committee in collaboration with student groups and facilities conducted a survey, resulting in the inclusion of more plant-based meal and snack options included in the campus cafÃ©â€™s daily offerings at affordable prices.â€¯Â Such wide-spanning efforts and resource dissemination through coursework, site visits, and both institutional and individual practices all support CEUâ€™s commitment to environmental responsibility.Â Â Read more news about sustainability, environment and energy studies at CEU.Â \n",
      "            News\n",
      "      \n",
      "            Department of Environmental Sciences and Policy\n",
      "      \n",
      "            Environmental and Energy Studies\n",
      "----------------------------------------\n",
      "\n",
      "âœ… Content extracted successfully\n"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "# Parse the HTML and extract content\n",
    "print(\"ğŸ” Parsing webpage content...\")\n",
    "\n",
    "try:\n",
    "    # Parse the HTML\n",
    "    webpage = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Extract title\n",
    "    title = webpage.title.string.strip()\n",
    "    print(\"\\nğŸ“‘ Page Title:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(title)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Extract paragraphs\n",
    "    print(\"\\nğŸ“ Article Content:\")\n",
    "    print(\"-\" * 40)\n",
    "    description_html = webpage.select(\".col-lg-8\")  # <----------------- !!! Our selector !!!\n",
    "    texts = [text.get_text().strip() for text in description_html]\n",
    "    text = \"\\n\".join(texts)\n",
    "    print(text)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nâœ… Content extracted successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error parsing content: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
